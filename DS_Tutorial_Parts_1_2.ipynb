{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS Tutorial Parts 1-2",
      "provenance": [],
      "collapsed_sections": [
        "9S_38ayWhm5W",
        "5lSgytL2f3OV",
        "5e6LtQ4p-B8U",
        "CcskjbCC2Re3",
        "LL7--Zxr1ad3",
        "CRYnEyir1B9p",
        "mv0UtLxzS8Uk",
        "x6iOBU-6f_dz",
        "dwgf8dhygGZS",
        "zxcPu65CU_4P",
        "Xl23_KkGV3_b",
        "-GmfP_LeEJO9",
        "6E6RWp7dtY6b",
        "CWSBrtaMtXkk",
        "osgyZ9Nj0_LQ",
        "rdw28x8xDkfQ",
        "SGXnn2WUjgag",
        "zvQxaNLLbeXb",
        "DO5ql9-vtk0H",
        "BU_kKlfq9VxK",
        "BIxBY1jR8svT",
        "9g5YLxpWNo0h",
        "fui5GF6-KQCX",
        "qIm6cjLqfaWB",
        "TnpeAv5pjQr4",
        "lOUo8icZuhI2",
        "lvj5ekalAw2y",
        "dhCZE54EA9Sc",
        "6Ys57PBauhRs",
        "a8dK0G_bldqw",
        "AaKY6dFVm2me",
        "TxZOxSxNHDIS",
        "6ZgOTdli4Gi3",
        "zgeYXh2GC1WF",
        "kndVlnjuHI34",
        "6s8EKaABJyBM",
        "Dekbfp9goUFJ",
        "Ec8midjSBJUg",
        "8__UNIH962G2",
        "32pRn7au6len",
        "H19D2ahHdTkK",
        "jE2TTKmgzwIP",
        "kblnhvBQ9GvC"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwWb0vH2iM6FElNDp4UIXc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinelK/IMBIZO2022_DS_Tutorial/blob/main/DS_Tutorial_Parts_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial:** Dynamical systems in neuroscience"
      ],
      "metadata": {
        "id": "9S_38ayWhm5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Dynamical systems are systems that **evolve** in time. These can be physical systems, economic systems, neurons, neural networks or the whole brain. No matter what the system is, the universal dynamical system framework can help us understand its time-dependent behavior.\n",
        "\n",
        "When modelling dynamics, we can represent time in two different ways: *discrete* or *continuous*. In both cases, we can write down the evolution of the system as a function of its previous `state' $\\mathbf{x}$ and external inputs that the system receives $\\mathbf{u}$:\n",
        "\n",
        "Discrete time systems               |           Continuous time systems\n",
        "------------------------------------|-------------------------------------\n",
        " $$\\mathbf{x}_{t+1} = F_d(\\mathbf{x}_t,\\mathbf{u}_t)$$           |    $$\\frac{d\\mathbf{x}(t)}{dt} = F_c(\\mathbf{x}(t),\\mathbf{u}(t))$$\n",
        " \n",
        "*Notation:* The variables in **bold** here correspond to vectors, e.g. $\\mathbf{x} = (x_1,x_2,\\ldots,x_n)^T$.\n",
        "\n",
        "Here, the state $\\mathbf{x}$ can, for instance, correspont to neural firing. In discrete case, $\\mathbf{x}_t$ would be the number of spikes emmited within one time bin, while $\\mathbf{x}(t)$ could be a function which is only non-zero at spike times.\n",
        "External inputs $\\mathbf{u}$ in this case would correspond to the inputs from other neurons.\n",
        "\n",
        "The key part of the dynamical systems framework is the **evolution function** $F$. Whether continuous $F_c$ or discrete $F_d$, it can tell us a lot about the system:\n",
        "> The power of the dynamical systems approach to neuroscience, as well as to many other sciences, is that we can tell something, or many things, about a system without knowing all the details that govern the system evolution. We do not even use equations to do that! Some may even wonder why we call it a mathematical theory.        *Eugene Izhikevich [1]*\n",
        "\n",
        "Therefore, the main goal of the tutorial is to learn how to tell something about the dynamical system knowing $F$."
      ],
      "metadata": {
        "id": "5lSgytL2f3OV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setups"
      ],
      "metadata": {
        "id": "5e6LtQ4p-B8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ipywidgets as widgets       # interactive display\n",
        "from matplotlib import rcParams\n",
        "from scipy.linalg import expm\n",
        "from scipy.optimize import minimize\n",
        "rcParams.update({'font.size': 18})"
      ],
      "metadata": {
        "id": "qH1B5GBH9969"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Autonomous linear dynamical systems (LDS)"
      ],
      "metadata": {
        "id": "N_XDFK9Xe9Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, we can assume that the system does not receive any external inputs and evolves in time on its own ( $u(t)=0$ ). Such dynamical systems are called **autonomous**. Autonomous systems are common in physics, but also surprisingly applicable to some biological neural networks, as we will see in the last part of the tutorial. Lack of external inputs greatly simplifies the analysis of the dynamics $F$, so let us assume **no** external inputs for now.\n",
        "\n",
        "As a warmup, let us start with a 1D autonomous continuous-time dynamical system:\n",
        "\n",
        "$\\frac{dx}{dt} = \\dot x = a x; \\qquad x(0) = x_0 \\tag{1} $\n",
        "\n",
        "We are looking at a so-called *initial value problem* here: we know the state of the system $x_0$ at $t=0$, but we want to make a forecast into the future and find $x(t)$ for $t>0$."
      ],
      "metadata": {
        "id": "1-CiIYrZ9wCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solving a 1D linear dynamics equation\n",
        "Let us solve equation (1) both numerically and analytically.\n",
        "\n",
        "For analytical solution, let us reorder the variables and integrate both sides of the equation just on paper:\n",
        "\n",
        "$$\\int_{x_0}^{x_t} \\frac{dx}{x} = \\int_{0}^t a dt \\tag{2a}$$\n",
        "\n",
        "For numerical integration, we will use the *forward Euler* scheme:\n",
        "\n",
        "$$\\frac{dx}{dt} \\approx \\frac{\\Delta x}{\\Delta t} = \\frac{x_{n+1} - x_n}{\\Delta t} \\tag{2b}$$\n",
        "\n",
        "We can then write down an analytical solution at any time point $t$ based on (2a), and also get a numerical approximation of the same integral by applying the update rule $x_{n+1} \\rightarrow x_n$ based on (2b) in a for-loop:"
      ],
      "metadata": {
        "id": "5ONwZE8bH5jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise 1:** Analytical vs numerical solutions\n",
        "Complete the missing lines in the code below. Does analytical solution match the numerical solution? "
      ],
      "metadata": {
        "id": "uOakw9zb3Rbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analytical_1D_solution(x0,a,t):\n",
        "  ''' Finds a solution of x' = ax, for x(t), given x(0) = x0 '''\n",
        "  #xt = ... # FILL IN\n",
        "  return xt\n",
        "\n",
        "def numerical_1D_solution(x0,a,t,dt=0.001):\n",
        "  ''' Integrates x' = ax using a forward Euler scheme, given x(0) = x0;\n",
        "  Returns x(t) '''\n",
        "  # N = ... # FILL IN the number of integration steps; Hint: use //, which is integer devision\n",
        "  xn = x0 # current value of x_n\n",
        "  for n in range(N):\n",
        "    #x_n_plus_1 = ... # FILL IN: write a discretized update rule following (1-2)\n",
        "    xn = x_n_plus_1  \n",
        "  return xn\n",
        "\n",
        "T = 1 # total duration\n",
        "n_plot = 10 # how many points to plot\n",
        "\n",
        "@widgets.interact\n",
        "def plot_1D_solutions(x0 = 1., \n",
        "                      a = widgets.FloatSlider(min=-2., max=2., step=1, value=1),\n",
        "                      dt = widgets.FloatLogSlider(min=-3, max=-1, value=.01)):\n",
        "  a = a if type(a)==float else a.value\n",
        "  dt = dt if type(dt)==float else dt.value\n",
        "  plt.figure()\n",
        "  time = np.linspace(0,T,n_plot)\n",
        "  plt.plot(time, [analytical_1D_solution(x0,a,t) for t in time],label='Analytical solution')\n",
        "  plt.plot(time, [numerical_1D_solution(x0,a,t,dt) for t in time],label='Numerical solution')\n",
        "  plt.xlim([0,T])\n",
        "  plt.ylim([-5,5])\n",
        "  plt.axhline(0,c='k',linestyle=':')\n",
        "  plt.xlabel('time')\n",
        "  plt.ylabel('state x')\n",
        "  plt.legend()\n"
      ],
      "metadata": {
        "id": "dwtnAtUPNkyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Think!**\n",
        "When do the solutions agree? Disagree? Why?\n"
      ],
      "metadata": {
        "id": "CcskjbCC2Re3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Think!**\n",
        "\n",
        "How many qualitatively different solutions have you found? What are they?\n"
      ],
      "metadata": {
        "id": "LL7--Zxr1ad3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxilary variables and phase portraits\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Mathematical_pendulum.svg/950px-Mathematical_pendulum.svg.png' width=200px align='right'>\n",
        "\n",
        "In Exercise 1 we have observed a 1D system can exponentially grow, decay, or stay the same. But we know that many systems in neuroscience do neither. They often oscillate!\n",
        "\n",
        "To get started with oscillations, let us consider another simple system that oscillates: a pendulum!\n",
        "\n",
        "The dynamics of the pendulum can be derived from first principles (Newton's laws of mechanics):\n",
        "\n",
        "$$\\ddot \\theta = - g \\sin(\\theta) \\approx -g \\theta$$\n",
        "\n",
        "which turns into a linear system if the oscillations are small ($\\theta \\ll 1$). We can further simplify the system by assuming $g=1$.\n",
        "\n",
        "This equation, however, contains a higher order derivative ($\\ddot \\theta$). How can we get rid of it?\n",
        "\n",
        "We can introduce an additional auxilary variable $\\omega = \\dot \\theta$, then:\n",
        "$$\\ddot \\theta = \\dot \\omega = -\\theta$$\n",
        "\n",
        "Now we have two equations that resemble (1), which we can combine into a single vector-valued equation for a state $\\mathbf{x} = [~\\theta,~\\omega~]^T$:\n",
        "\n",
        "$${\\begin{bmatrix}\n",
        "    \\dot \\theta \\\\\n",
        "    \\dot \\omega\n",
        "\\end{bmatrix}} = \\begin{bmatrix}\n",
        "    0 & 1 \\\\\n",
        "    -1 & 0\n",
        "\\end{bmatrix} \\begin{bmatrix}\n",
        "    \\theta \\\\\n",
        "    \\omega\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "or simply:\n",
        "\n",
        "$$\\mathbf{\\dot x} = A \\mathbf{x} \\tag{3}$$\n",
        "\n",
        "Looks similar to the 1D system in (1). Then how does it produce \n",
        "oscillations? 🤔 Let's find out.\n"
      ],
      "metadata": {
        "id": "42ptqWjfHdKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 2:** Solving a 2D linear dynamics equation"
      ],
      "metadata": {
        "id": "CRYnEyir1B9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the missing line of code below to numerically integrate the eq. (3).\n",
        "\n",
        "*Hint: for matrix multiplication in python you can use @ sign*\n",
        "\n",
        "*Note:* the analytical solution of eq. (3) is given to you in the code. It involves matrix exponential. If you don't know what it is -- no worries, it is not important for this tutorial."
      ],
      "metadata": {
        "id": "PYEkx4i3a4WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analytical_2D_solution(x0,A,t):\n",
        "  ''' Finds a solution of x' = Ax, for x(t), given x(0) = x0 '''\n",
        "  xt = expm(A*t) @ x0 # this solution includes matrix exponential (https://en.wikipedia.org/wiki/Matrix_exponential)\n",
        "  return xt\n",
        "\n",
        "def numerical_2D_solution(x0,a,t,dt=0.01):\n",
        "  ''' Integrates x' = Ax using a forward Euler scheme, given x(0) = x0;\n",
        "  Returns x(t) '''\n",
        "  N = int(t//dt) # number of integration steps\n",
        "  xn = x0 # current value of x_n\n",
        "  for n in range(N):\n",
        "    # x_n_plus_1 = ... # FILL IN: write a discretized update rule following (1-2)\n",
        "    xn = x_n_plus_1  \n",
        "  return xn\n",
        "\n",
        "T = 10 # total duration\n",
        "n_plot = 100 # how many points to plot\n",
        "\n",
        "A = np.array([[0, 1], [-1, 0]])\n",
        "\n",
        "@widgets.interact\n",
        "def plot_2D_solutions(phi0 = (-1,1,0.1),\n",
        "                      omega0 = (-1,1,0.1)):\n",
        "  x0 = np.array([phi0, omega0])\n",
        "  fig, axes = plt.subplots(1,3,figsize=(12,2),gridspec_kw={'width_ratios': [2, 1, 2]})\n",
        "  time = np.linspace(0,T,n_plot)\n",
        "  analytical_traj = np.array([analytical_2D_solution(x0,A,t) for t in time])\n",
        "  numerical_traj = np.array([numerical_2D_solution(x0,A,t) for t in time])\n",
        "  \n",
        "  axes[1].plot(*numerical_traj.T,c='k')\n",
        "  axes[1].plot(*analytical_traj.T,c='C1',linestyle=':')\n",
        "  axes[1].set_xlabel(r\"$\\theta$\")\n",
        "  axes[1].set_ylabel(r\"$\\omega = \\dot\\theta$\")\n",
        "  axes[1].set_xlim([-1.2,1.2])\n",
        "  for ax in axes:\n",
        "    ax.set_ylim([-1.2,1.2])\n",
        "\n",
        "  axes[0].plot(numerical_traj[:,0],c='k')\n",
        "  axes[0].plot(analytical_traj[:,0],c='C1',linestyle=':')\n",
        "  axes[0].set_xlabel(r\"time\")\n",
        "  axes[0].set_ylabel(r\"$\\theta$\")\n",
        "\n",
        "  axes[2].plot(numerical_traj[:,1],c='k',label='Numerical solution')\n",
        "  axes[2].plot(analytical_traj[:,1],c='C1',linestyle=':',label='Analytical solution')\n",
        "  axes[2].set_xlabel(r\"time\")\n",
        "  axes[2].set_ylabel(r\"$\\omega = \\dot\\theta$\")\n",
        "  axes[2].legend(loc=(1.2,0))\n",
        "\n",
        "  plt.subplots_adjust(left=None, bottom=.2, right=None, top=None, wspace=0.4, hspace=0.)"
      ],
      "metadata": {
        "id": "iKjR6PFOTIU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot in the middle is called a *phase portrait* in mechanics: you can see why if you change the angular velocity $\\omega$ and see how left/right plots change. This portrait exists in a *phase space* $[\\theta, \\omega]$.\n",
        "\n",
        "In physics, we can derive the dynamics equations from first principles, so we know that these two variables: position $\\theta$ and angular velocity $\\omega$, fully describe the **state** of the pendulum. Knowing the state, we know what happens next, because the system is **deterministic** (no noise in eq. (1) or (3)).\n",
        "Therefore, in a more general context, a minimal set of variables that describe the state of the system form a **state space**. \n",
        "\n",
        "<!-- However, in a more general context, the components of $x$ that describe the dynamics of the system can be anything! For instance, $x_1, x_2, \\ldots, x_n$ can correspond to activities of neurons in a neural network.    -->\n"
      ],
      "metadata": {
        "id": "cHFFvDETs291"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing dynamics: phase portraits"
      ],
      "metadata": {
        "id": "mv0UtLxzS8Uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have learned that if we know the state of the the system at any time point $t_0$, we can predict what happes next. We already integrated the dynamics eq. (3) given certain initial conditions and visualized some trajectories for a pendulum. But can we summarize and visualize all the possible states and transitions between them?\n",
        "\n",
        "We can visualize the equation (3) using stream plots. For every state, equation (3) defines the derivative (i.e. where the system goes next), which we can visualize with arrows:\n"
      ],
      "metadata": {
        "id": "eILlepzLTDd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting phase portraits\n",
        "def plot_phase_portrait(A,n = 10, xlabel=r'$x_1$', ylabel=r'$x_2$', Alabel='A'):\n",
        "  '''\n",
        "    A: matrix 2x2\n",
        "    n: number of points in the n x n grid\n",
        "  '''\n",
        "  plt.figure(figsize=(3,3))\n",
        "  x1 = np.linspace(-1, 1, n) # a 1D grid\n",
        "  x = np.array(np.meshgrid(x1, x1)).reshape((2,-1)) # a 2D flattened grid\n",
        "  # calculate the time-derivative of the state x in the line below\n",
        "  # the output shape should be [2 x n^2]\n",
        "  # x_dot = ...  # FILL IN\n",
        "  x_dot = x_dot.reshape((2,n,n))\n",
        "  plt.streamplot(x1,x1,*x_dot,color=np.linalg.norm(x_dot,axis=0),cmap='coolwarm',density=0.5)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel);\n",
        "  plt.text(1.2,0,f'{Alabel} = ')\n",
        "  plt.text(1.7,-.15,f'{A[0,0]:.1f}, {A[0,1]:.1f} \\n{A[1,0]:.1f}, {A[1,1]:.1f}')\n",
        "  plt.xlim([-1,1])\n",
        "  plt.ylim([-1,1])\n",
        "  plt.clim(vmin=0,vmax=1)\n",
        "\n",
        "A = np.array([[0, 1], [-1, 0]]) # pendulum dynamics\n",
        "plot_phase_portrait(A, xlabel=r'$\\theta$', ylabel=r'$\\omega = \\dot\\theta$')"
      ],
      "metadata": {
        "id": "yfeWdEMsVcks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following these streamlines in a figure above from some initial point $x_0$ step-by-step corresponds to integrating $\\int_{t_0}^{t} \\dot x(t) dt$ that we did in the previous exercise!\n",
        "\n",
        "Color here shows how fast the state evolves: cooler colors mean slower, warmer colors -- faster!\n",
        "(darkest blue: $|\\mathbf{\\dot x}| = 0$, brightest red: $|\\mathbf{\\dot x}| = 1$)\n",
        "\n",
        "Like in Izhekevich quote, we don't even need to write equation to tell how the system behaves 🤯"
      ],
      "metadata": {
        "id": "b7dTSLXUYUDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing multi-dimensional linear dynamical systems"
      ],
      "metadata": {
        "id": "x6iOBU-6f_dz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change of basis\n",
        "The pendulum example above is, perhaps, the simplest linear dynamical system in physics. Its phase portrait is symmetrical!\n",
        "\n",
        "But for other dynamical systems, with other matrices $A$, this might not be the case:"
      ],
      "metadata": {
        "id": "dwgf8dhygGZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2)\n",
        "A = np.random.randn(2,2) # pick some values from N(0,1) for each component\n",
        "\n",
        "plot_phase_portrait(A)\n"
      ],
      "metadata": {
        "id": "if2U5CDUaj9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks very complicated! All elements in $A$ are non-zero, so each derivative $\\dot x_i$ depends on both $x_1$ and $x_1$. Can we make it better? Can we somehow split a 2D system into a combination of two 1D systems?\n",
        "\n",
        "We are now considering an abstract linear dynamical system, so the components $x_1$ and $x_2$ do not mean much... Can we stretch and rotate this space such that in these new coordinates $(\\hat x_1, \\hat x_2)$  the derivatives $d{\\hat x_i}/dt$ only depend on the respective component $x_i$ ? Or, in other words, can we change the basis to make the matrix $A$ diagonal?\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "\\frac{d\\hat x_1}{dt} \\\\\n",
        "\\frac{d\\hat x_2}{dt}\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "a_1 & 0 \\\\\n",
        "0 & a_2\n",
        "\\end{bmatrix} \\begin{bmatrix}\n",
        "\\hat x_1 \\\\\n",
        "\\hat x_2\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "a_1 \\hat x_1 \\\\\n",
        "a_2 \\hat x_2\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "vDZ9Dj6LQ6fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S = np.eye(2)\n",
        "@widgets.interact\n",
        "def rotate_and_scale(stretch=widgets.FloatLogSlider(min=-1, max=+1, value=1.,description='stretch ↕'),\n",
        "                     rotate=widgets.FloatSlider(min=-90, max=+90, step=5 ,description='rotate ⤾')):\n",
        "  global S\n",
        "  a = rotate * np.pi / 180\n",
        "  S =  np.array([[np.cos(a),np.sin(a)],[-np.sin(a),np.cos(a)]]) @ np.array([[stretch,0],[0,1]])\n",
        "  plot_phase_portrait(S @ A @ np.linalg.inv(S),\n",
        "                      xlabel=r'$\\hat{x_1}$', ylabel=r'$\\hat{x_2}$', Alabel=r'$\\hat{A}$')\n"
      ],
      "metadata": {
        "id": "JM-JOpEvQ5OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we are doing above corresponds to this transformation:\n",
        "$$S \\mathbf{\\dot x} = SA\\mathbf{x} = SA\\underbrace{(S^{-1}S)}_{I}\\mathbf{x} = (SAS^{-1})S\\mathbf{x}$$\n",
        "or, in other words, we make the following change of coordinates (i.e. change of the basis):\n",
        "$$\\mathbf{x} \\rightarrow S\\mathbf{x} ~$$\n",
        "$$A \\rightarrow SAS^{-1}$$"
      ],
      "metadata": {
        "id": "VzGbCtBQR9PC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Think!\n",
        "Did you manage to align most of the arrows in the phase portrait above with the new axes? How does the new, transformed matrix $\\hat{A} = SAS^{-1}$ look like?"
      ],
      "metadata": {
        "id": "zxcPu65CU_4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eigenvectors and eigenvalues"
      ],
      "metadata": {
        "id": "Xl23_KkGV3_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we did above in fact corresponds to the eigendecomposition.\n",
        "For more info check Chris's tutorial [Appendix](https://colab.research.google.com/drive/1AH5_d_uJTnJMUANGt9XIIkkg8n2Tur4s).\n",
        "\n",
        "The key points that we need from this Appendix:\n",
        "\n",
        "Eigendecomposition of a matrix is a type of decomposition that involves decomposing a **square** ($n \\times n$) matrix into a **set** of *eigenvectors* and *eigenvalues*.\n",
        "\n",
        "A vector $\\rm{x}$ is an eigenvector of a matrix $A$ if it satisfies the following equation.\n",
        "\n",
        "$A\\rm{x} = \\lambda \\rm{x} \\tag{E.1}$\n",
        "\n",
        "This is called the eigenvalue equation, where $A$ is the parent square matrix that we are decomposing, $x$ is the eigenvector of the matrix, and $\\lambda$ is the lowercase Greek letter lambda and represents the eigenvalue scalar.\n",
        "\n",
        "This can also be rearranged into\n",
        "\n",
        "$(A-\\lambda I)\\rm{x} = 0 \\tag{E.2}$\n",
        "\n",
        "Where $I$ is the square identity matrix ($1$s in its main diagonal and $0$s in every other entry) with the same dimensions as $A$. \n",
        "\n",
        "In order to determine the all eigenvectors of a matrix, you must first determine the eigenvalues. \n",
        "\n",
        "Non-trivial solutions exist only if the matrix ($A-\\lambda I$) is non-invertible which means $\\det(A-\\lambda I) = 0$. Where $\\det(M)$ or $|M|$ is the [determinant](https://en.wikipedia.org/wiki/Determinant) of the matrix.\n",
        "\n",
        "Therefore eigenvalues of $A$ are roots of the [characteristic polynomial](https://en.wikipedia.org/wiki/Characteristic_polynomial)\n",
        "\n",
        "$p(\\lambda) = \\det(A-\\lambda I) \\tag{E.3}$"
      ],
      "metadata": {
        "id": "rywINi0N5Lzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Think!**\n",
        "\n",
        "What is the order of the polynomial for a 2D matrix $A$? How many roots will it have?"
      ],
      "metadata": {
        "id": "-GmfP_LeEJO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Real eigenvalues"
      ],
      "metadata": {
        "id": "6E6RWp7dtY6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we did above by rotating and stretching our phase space is the transformation of matrix $A$ into its *canonical form*. Everything is simpler in this form! The eigenvalues remain the same under stretching and rotation:\n",
        "\n",
        "$$\\hat{A}\\mathbf{\\hat{x}} = SA\\mathbf{x} = S\\lambda x = \\lambda \\mathbf{\\hat{x}}$$\n",
        "\n",
        "Could you tell what are the eigenvalues of $\\hat{A}$ without writing anything down?\n",
        "\n",
        "Now, check your guess by calculating the eigenvalues:\n"
      ],
      "metadata": {
        "id": "2qpJ7QCvVy2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_hat = S @ A @ np.linalg.inv(S)\n",
        "print('Eigenvalues of A    :', np.linalg.eig(A)[0])\n",
        "print('Eigenvalues of A_hat:', np.linalg.eig(A_hat)[0])"
      ],
      "metadata": {
        "id": "8rc4t1cfUCCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us experiment with the eigenvalues and understand what they *mean* in the dynamical system:"
      ],
      "metadata": {
        "id": "5OeSIGu0equz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@widgets.interact\n",
        "def rotate_and_scale(lambda_1=widgets.FloatSlider(min=-1, max=+1, description='λ1'),\n",
        "                     lambda_2=widgets.FloatSlider(min=-1, max=+1, description='λ2')):\n",
        "  lambda_1 = lambda_1 if type(lambda_1)==float else lambda_1.value\n",
        "  lambda_2 = lambda_2 if type(lambda_2)==float else lambda_2.value\n",
        "  if lambda_1==0 and lambda_2==0:\n",
        "    lambda_1 = -1e-10\n",
        "  A_12 = np.array([[lambda_1, 0],\n",
        "                [0, lambda_2]])\n",
        "  plot_phase_portrait(A_12)\n"
      ],
      "metadata": {
        "id": "Z8CeIjn5Z2KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, in a canonical form, the 2D system with two real eigenvalues splits into two independent 1D dynamical systems:\n",
        "$\\dot x_i = \\lambda_i x_i, i \\in \\{0,1\\}.$ So, each eigenvalue here changes the dynamics along its eigenvector the same way as the parameter $a$ in Example 1."
      ],
      "metadata": {
        "id": "jurO9-jFnwus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The eigenvectors are trivial in the canonical form: they are just aligned with axes!\n",
        "\n",
        "So, in order to find eigenvectors of the original evolution matrix $A$, we simply need to reverse the rotation and stretching:"
      ],
      "metadata": {
        "id": "EZ8BnuxTpHg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_hat = S @ A @ np.linalg.inv(S)\n",
        "print('Trivial eigenvectors of A_hat:', np.round(np.linalg.eig(A_hat)[1].T,1))\n",
        "print('Eigenvectors of A:', np.round(np.linalg.eig(A)[1].T,2))\n",
        "S_inv = np.linalg.inv(S) # invert the transform\n",
        "S_inv_norm = S_inv / np.linalg.norm(S_inv,axis=0)\n",
        "print('Vectors derived from transformation:', np.round(S_inv_norm.T,2))"
      ],
      "metadata": {
        "id": "waP_Yj2GpiT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above vectors should be the almost identical (up to a sign)."
      ],
      "metadata": {
        "id": "7WrGlWwitJr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Complex eigenvalues"
      ],
      "metadata": {
        "id": "CWSBrtaMtXkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From a characteristic polynomial, we know that the eigenvalues can be complex (as $\\lambda = \\lambda_{real} + i \\lambda_{imag}$). We also found that eigenvalues connect high-dimensional systems (e.g. 2D) with some lower-dimensional (e.g. 1D) dynamic modes. Let us go back to a 1D system and try to make a coefficient $a$ complex."
      ],
      "metadata": {
        "id": "jUG_eBfrxgzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 3: What if $a$ is complex-valued?"
      ],
      "metadata": {
        "id": "osgyZ9Nj0_LQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the exercise 1 we found that analytical solution is:\n",
        "$$x(t) = x_0 e^{at} $$\n",
        "but what if $a$ is complex?\n",
        "\n",
        "Let us substitute $a$ with $a_{real} + i a_{imag}$, then:\n",
        "$$x(t) = x_0 e^{a_{real}t} e^{i a_{imag} t} $$\n",
        "\n",
        "This new solution is a product of the solution that we have seen previously and a new term $e^{i a_{imag} t}$.\n",
        "\n",
        "Let us generate some trajectories and see what happens:\n"
      ],
      "metadata": {
        "id": "Xcd8cBTmCHPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@widgets.interact\n",
        "def plot_1D_solutions(x0 = 1., \n",
        "                      a_real = widgets.FloatSlider(min=-1., max=1., step=.1, value=0),\n",
        "                      a_imag = widgets.FloatSlider(min=-1, max=5, step=.1, value=1)):\n",
        "  a_real = a_real if type(a_real)==float else a_real.value\n",
        "  a_imag = a_imag if type(a_imag)==float else a_imag.value\n",
        "  a = complex(a_real,a_imag) # creating a complex number in Python\n",
        "  plt.figure()\n",
        "  time = np.linspace(0,T,n_plot)\n",
        "  # we are reusing the 1D analytical solution you made above\n",
        "  plt.plot(time, [analytical_1D_solution(x0,a,t).real for t in time],label='Solution (real part)')\n",
        "  plt.plot(time, [analytical_1D_solution(x0,a,t).imag for t in time],label='Solution (imag part)')\n",
        "  plt.xlim([0,T])\n",
        "  plt.ylim([-5,5])\n",
        "  plt.axhline(0,c='k',linestyle=':')\n",
        "  plt.xlabel('time')\n",
        "  plt.ylabel('state x')\n",
        "  plt.legend(loc='lower left')\n"
      ],
      "metadata": {
        "id": "-OCLpgAhA2od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Let us recall that $e^{i a_{imag} t} = \\cos(a_{imag} t) + i\\sin(a_{imag} t)$ (*Euler's formula*).\n",
        "\n",
        " So the whole solution looks like:\n",
        " $$x(t) = \\underbrace{x_0 e^{a_{real} t} \\cos(a_{imag}t)}_\\mathrm{real~part} + \\underbrace{i x_0 e^{a_{real} t} \\sin(a_{imag}t)}_\\mathrm{imaginary~part}$$\n"
      ],
      "metadata": {
        "id": "3zzMK8fmEjJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us return to the pendulum. What are the eigenvalues and eigenvectors for that 2D system?"
      ],
      "metadata": {
        "id": "1cdUYs1PFjOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[0, 1], [-1, 0]])\n",
        "np.linalg.eig(A)"
      ],
      "metadata": {
        "id": "KKXWSV7hj-LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Think!**\n",
        "\n",
        "What is the frequency of oscillations, based on these eigenvalues?"
      ],
      "metadata": {
        "id": "rdw28x8xDkfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zero eigenvalues\n",
        "\n",
        "So far, we only looked at a full rank matrices $A$: such matrices that have all non-zero eigenvectors. What if one of them is actually zero?"
      ],
      "metadata": {
        "id": "SGXnn2WUjgag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@widgets.interact\n",
        "def rotate_and_scale(lambda_1=widgets.FloatSlider(min=-1, max=+1, description='λ1'),\n",
        "                     lambda_2=widgets.FloatSlider(min=-1, max=+1, description='λ2')):\n",
        "  lambda_1 = lambda_1 if type(lambda_1)==float else lambda_1.value\n",
        "  lambda_2 = lambda_2 if type(lambda_2)==float else lambda_2.value\n",
        "  if lambda_1==0 and lambda_2==0:\n",
        "    lambda_1 = -1e-10\n",
        "  A_12 = np.array([[lambda_1, 0],\n",
        "                [0, lambda_2]])\n",
        "  plot_phase_portrait(A_12)"
      ],
      "metadata": {
        "id": "kJWsZ2Tc6Z85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed points and stability\n",
        "\n",
        "**Fixed points** are the points that remain unchanged in time, meaning that the time derivative $\\mathbf{\\dot x}=\\mathbf{0}$ there. There is only one such point in the linear systems which we considered above, which is $\\mathbf{x}=\\mathbf{0}$.\n",
        "\n",
        "Fixed points can be stable and unstable. Stable means that once the state gets near the fixed point it will only get closer to it in the future (*more precisely it is called assymptotic stability*). Unstable means the opposite: the state only gets further away. The system can also be marginally stable, if it is neither stable nor unstable. \n",
        "\n",
        "A set of stable fixed points of a dynamical system is also called an **attractor**, while a set of unstable points -- a **repeller**.\n",
        "\n",
        "If matrix $A$ has two eigenvalues: $\\lambda_1$ and $\\lambda_2$, what are the conditions for being 1) stable? 2) unstable?"
      ],
      "metadata": {
        "id": "zvQxaNLLbeXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "We have explored DS with real-valued, complex and zero eigenvalues. And that is all possible dynamics one can get in 2D with a linear DS!\n",
        "\n",
        "We can summarize all dynamic regimes in a single plot:\n",
        "\n",
        "![Classification of Phase Portraits](https://drive.google.com/uc?export=view&id=1zvbMnqnSFiss3GF_yfUo83NxOD_WXZtK)\n",
        "\n",
        "here $\\Delta = (\\lambda_1 - \\lambda_2)^2$ sets the boundary between real-valued and complex-valued eigenvalues (you can also derive it from a characteristic polynomial)"
      ],
      "metadata": {
        "id": "DO5ql9-vtk0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 4**: relationship between continuous time and discrete time linear dynamical systems\n",
        "\n",
        "In the exercise above we were visualizing phase planes for the *continuous-time* dynamical systems. It is convinient, because there exists a derivative $\\mathbf{\\dot x}$, which we were plotting with streamplots.\n",
        "\n",
        "However, when it comes to **numerical** integration, we typically use discrete time steps. We already applied one such discretization ( a forward Euler scheme) in Exercise 1.\n",
        "\n",
        "Discrete time LDS               |           Continuous time LDS\n",
        "------------------------------------|-------------------------------------\n",
        " $$\\mathbf{x}_{t+1} = A_d \\mathbf{x}_t$$           |    $$\\frac{d\\mathbf{x}(t)}{dt} = A_c\\mathbf{x}(t)$$"
      ],
      "metadata": {
        "id": "svmBduOG_52v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4a: Relationship between evolution matrices\n",
        "\n",
        "In this exercise, let us find the relationship between the continuous-time evolution matrix $A_c$ and the discrete-time matrix $A_d$ using forward Euler discretization. If we discretize the continuous system, then what would be the equivalent of a matrix $A_d$ in a discretized version?"
      ],
      "metadata": {
        "id": "BU_kKlfq9VxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4b: Relationship between eigenspectra*\n",
        "\\**difficult exercise, you can check the solution if no time*\n",
        "\n",
        "What eigenvalues of matrices $A_c$ and $A_d$ define a marginally stable system (that neither explodes, nor collapses)? Draw both margins of stability on a complex plane."
      ],
      "metadata": {
        "id": "BIxBY1jR8svT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 5:** practice reading eigenspectra from papers"
      ],
      "metadata": {
        "id": "9g5YLxpWNo0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### A spectrum of a continuous linearized E-I network\n",
        "\n",
        "How does this continuous system behave? \n",
        "What dynamic modes do these eigenvalues describe?\n",
        "Which eigenvalues are dominant?\n",
        "\n",
        "![spectrum1](https://drive.google.com/uc?export=view&id=1OHb8jNNET8VFcBZtPhVCEqVBV8jmLguC)"
      ],
      "metadata": {
        "id": "fui5GF6-KQCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "In the first part of this tutorial, we learned:\n",
        "\n",
        "1. What linear systems can and can not do\n",
        "2. What fixed points are and how to check their stability\n",
        "3. How to read eigenspectra\n",
        "\n",
        "Now together we'll figure out:\n",
        "4. How is it related to different computations (whiteboard)\n"
      ],
      "metadata": {
        "id": "qIm6cjLqfaWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Nonlinear dynamical systems"
      ],
      "metadata": {
        "id": "_8WO8jlefRx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimensionality reduction on Hodgkin-Huxley model\n",
        "\n",
        "Yesterday you have run simulations of a biophysically accurate neuron models with a Hodgkin-Huxley equation (HH). To recap, the set of HH equations contained the following 4 equations:\n",
        "\n",
        "$$C \\frac{dV}{dt} = -\\bar g_K n^4 (V - V_K) - \\bar g_{Na} m^3 h(V-V_{Na}) - \\bar g_l (V - V_l) + I_{ext}\\tag{4a}$$\n",
        "\n",
        "$$\\frac{dn}{dt} = \\alpha_n(V)(1-n) - \\beta_n(V) n\\tag{4b}$$\n",
        "$$\\frac{dm}{dt} = \\alpha_m(V)(1-m) - \\beta_m(V) m\\tag{4c}$$\n",
        "$$\\frac{dh}{dt} = \\alpha_h(V)(1-h) - \\beta_h(V) h\\tag{4d}$$\n",
        "\n",
        "The state space of this model is 4D, which is too much for visualization and analyse.\n",
        "However, not all equations here are equally important. \n",
        "\n",
        "![Gate timescales](https://neuronaldynamics.epfl.ch/online/x27.png) | ![Activation-inactivation gates](https://neuronaldynamics.epfl.ch/online/x26.png)\n",
        ":------------------------------------:|:-------------------------------------:\n",
        "**Fig. 1a**  The voltage dependent time constants | **Fig. 1b** The equilibrium functions for the three variables m,n,h"
      ],
      "metadata": {
        "id": "TnpeAv5pjQr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1. Time scale separation between fast ($V$) and very-fast ($m$) variables\n",
        "\n",
        "  First, we can look at the timescales of different equations (Fig. 1a).  We see that sodium channel activation $m$ changes much faster than other gating variables, faster than a single spike ($<$1ms).\n",
        "Therefore, we can assume that equation (4c) always quickly reaches equilibrium $dm/dt=0$, and substitute eq. (4c) with a *quasi-steady state* approximation $m(t) = m_0(V(t))$. Thus, we get rid of a differential equation (4c)."
      ],
      "metadata": {
        "id": "lOUo8icZuhI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2. Merging two similar slow equations ($n$ and $h$)\n",
        "\n",
        "  From Fig.1a we also see that both sodium channel inactivation $h$ and potassium channel gating $n$ change slowly (on a scale of 5-10ms). We can also notice that in Fig.1b $n(V)$ looks roughly like $1-h(V)$ (not exactly, but it is an approximation).\n",
        "So, since these two variables have similar dependencies on both time and voltage, we can substitute them with a single variable $w$ that approximates both gating variables. Thus, we merge eq. (4b) and (4d) into one. "
      ],
      "metadata": {
        "id": "lvj5ekalAw2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result: 2D FitzHugh-Nagumo (FHN) model\n",
        "\n",
        "Following 2 steps above, we merged 2 **fast** equations and 2 **slow** equations, which results in the following model:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathrm{\\mathbf{Fast:}} \\quad\\frac{dV}{dt} &= V(1-V)(V-V_{thr}) - w + i_{ext} \\tag{5a}\\\\\n",
        "\\mathrm{\\mathbf{Slow:}} ~\\quad \\frac{dw}{dt} &= \\epsilon (\\beta V - w) \\tag{5b}\n",
        "\\end{align}\n",
        "\n",
        "here some coefficients like time constants and capacitance of the membrane are typically omitted for simplicity.\n",
        "\n",
        "The two equations are also often called **fast activator** and **slow inhibitor**. Because the first equation describes cell's depolarization and sodium channel opening (activation), while the second equation describes everything that works towards repolarization (potassium currents + sodium channels' inactivation).\n",
        "The parameter responsible for fast/slow timescales separation is $\\epsilon$, which is typically set to $0.01$ (i.e. 5b is 100x slower than 5a).\n",
        "\n",
        "Now that we have a 2D system, we can visualize its phase portrait!"
      ],
      "metadata": {
        "id": "dhCZE54EA9Sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase portrait of FHN"
      ],
      "metadata": {
        "id": "6Ys57PBauhRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting phase portraits\n",
        "def plot_FHN_phase_portrait(i_ext,V_thr,beta,\n",
        "                            V_null = None, w_null = None,\n",
        "                            V_min = -.5, V_max = 1.2,\n",
        "                            w_min = -.1, w_max = .2,\n",
        "                            eps=0.01,n=30):\n",
        "  '''\n",
        "    Plots a phase portrait for a FitzHugh-Nagumo model (eq. 5)\n",
        "    n: number of points in the n x n grid\n",
        "  '''\n",
        "  plt.figure(figsize=(5,5))\n",
        "  V_grid = np.linspace(V_min,V_max, n) # a 1D activator grid\n",
        "  w_grid = np.linspace(w_min,w_max, n) # a 1D inhibitor grid\n",
        "  x = np.array(np.meshgrid(V_grid, w_grid)).reshape((2,-1)) # a 2D flattened grid\n",
        "  V, w = x\n",
        "  # V_dot = ... # FILL IN \n",
        "  # w_dot = ... # FILL IN\n",
        "  plt.streamplot(V_grid,w_grid,V_dot.reshape(n,n),w_dot.reshape(n,n),\n",
        "                 color=np.linalg.norm(np.array([V_dot,w_dot]),axis=0).reshape(n,n),\n",
        "                 cmap='coolwarm',density=1.5)\n",
        "  if V_null is not None:\n",
        "    plt.plot(V_grid,V_null(V_grid,V_thr,i_ext),c='k')\n",
        "  if w_null is not None:\n",
        "    plt.plot(V_grid,w_null(V_grid,beta),c='k')\n",
        "  plt.xlabel('fast activator V')\n",
        "  plt.ylabel('slow inhibitor w')\n",
        "  plt.xlim([V_min,V_max])\n",
        "  plt.ylim([w_min,w_max])\n",
        "  plt.clim(vmin=0,vmax=.2)\n",
        "\n",
        "@widgets.interact\n",
        "def interactive_FHN_portrait(i_ext=widgets.FloatSlider(min=-.2, max=.3, value=0), \n",
        "                            V_thr=widgets.FloatSlider(min=0, max=1, value=0.2),\n",
        "                            beta=widgets.FloatSlider(min=0.05, max=.5, value=.4),):\n",
        "  plot_FHN_phase_portrait(i_ext,V_thr,beta)"
      ],
      "metadata": {
        "id": "6D5fBETVZ6Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks very complicated! Although, if we look at some parts of the phase plane, locally it might resemble some of the patterns of an LDS behavior that we have seen before. (by the way, which ones?)"
      ],
      "metadata": {
        "id": "ObkUx2cci1Ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed points, nullclines, stability"
      ],
      "metadata": {
        "id": "a8dK0G_bldqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While linear systems had just one fixed point, non-linear systems can have many. Moreover, even the number of fixed points can change depending on the parameters (like $V_{thr}$ or $\\gamma$) 🤯\n",
        "\n",
        "We can find fixed points, by dealing with equations (5a) and (5b) one by one. The set of points where $\\dot V = 0$ is called **$V$-nullcline**. Nullclines divide the phase plane into two parts, based on the sign on the derivative. \n",
        "\n",
        "Let us add the nullclines to the phase portrait. We will define them as functions + learn an additional way to define single-expression functions in python: "
      ],
      "metadata": {
        "id": "HDqho-8NbtED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V_nullcline = None\n",
        "w_nullcline = None\n",
        "@widgets.interact\n",
        "def interactive_FHN_portrait(i_ext=widgets.FloatSlider(min=-.2, max=.3, value=0,step=.01), \n",
        "                            V_thr=widgets.FloatSlider(min=0, max=1, value=0.2),\n",
        "                            beta=widgets.FloatSlider(min=0.05, max=.5, value=.4, step=0.01),):\n",
        "\n",
        "  global V_nullcline, w_nullcline\n",
        "\n",
        "  # There are two ways to define functions in python.\n",
        "  # 1. def name(args): (function)\n",
        "  #       ... some computations\n",
        "  #       return output\n",
        "  # 2. name = lambda args: output (a lambda-function: 1) has one expression for outputs; 2) does not have to have a name)\n",
        "\n",
        "  # # write equations for nullclines as a function of V: lambda-way\n",
        "  # V_nullcline = lambda V, V_thr, i_ext: # FILL IN\n",
        "  # w_nullcline = lambda V, beta: # FILL IN\n",
        "\n",
        "  # # write equations for nullclines as a function of V: standard-way\n",
        "  # def V_nullcline(V, V_thr, i_ext):\n",
        "  #   return # FILL IN\n",
        "  # def w_nullcline(V, beta):\n",
        "  #   return # FILL IN\n",
        "\n",
        "  plot_FHN_phase_portrait(i_ext,V_thr,beta,\n",
        "                          V_null = V_nullcline, w_null = w_nullcline)"
      ],
      "metadata": {
        "id": "opUPiBLNleoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 5: FHN fixed points\n",
        "What is the minimal and maximal number of fixed points we can get?"
      ],
      "metadata": {
        "id": "AaKY6dFVm2me"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysing stability"
      ],
      "metadata": {
        "id": "TxZOxSxNHDIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Local stability"
      ],
      "metadata": {
        "id": "6ZgOTdli4Gi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Suppose the nullclines are intersecting somewhere in the middle, like this:"
      ],
      "metadata": {
        "id": "fe-e7EvTHBLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i_ext, V_thr, beta = 0.1, 0.2, 0.4\n",
        "plot_FHN_phase_portrait(i_ext,V_thr,beta,\n",
        "                        V_max=1.3, w_min=0, w_max=.3,\n",
        "                        V_null = V_nullcline, w_null = w_nullcline)"
      ],
      "metadata": {
        "id": "3dx6tecc5i8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that globally, in the whole phase plane, the arrows that indicate the derivative $\\mathbf{\\dot x} = [\\dot V, \\dot w]^T$ change their directions in non-trivial ways, because $\\mathbf{\\dot x} = F(\\mathbf{x})$ is non-linear. \n",
        "\n",
        "However, we can locally **linearize** the dynamical system:  approximate the the evolution operator $F(.)$ with a linear function:\n",
        "\n",
        "$$\\mathbf{\\dot x} = F(\\mathbf{x}) \\approx \\mathbf{F_0} +  \\left.\\frac{\\partial \\mathbf{F}}{\\partial \\mathbf{x}}\\right |_{x_0} \\mathbf{x} = \\mathbf{F_0} + \n",
        "\\begin{bmatrix}\n",
        "    \\frac{\\partial F_V}{\\partial V} & \\frac{\\partial F_V}{\\partial w}\\\\\n",
        "    \\frac{\\partial F_w}{\\partial V} & \\frac{\\partial F_w}{\\partial w}\n",
        "\\end{bmatrix}_{\\mathbf{x}_0}  \\mathbf{x}$$\n",
        "\n",
        "If we linearize about a randomly picked point on the phase plane, we'll get an additional non-zero term $\\mathbf{F_0}$.\n",
        "\n",
        "But if $\\mathbf{x}_0$ is a fixed point, then:\n",
        "\n",
        "$$\\mathbf{\\dot x} = \\frac{d(\\mathbf{x - x_0})}{dt} = \n",
        "\\begin{bmatrix}\n",
        "    \\frac{\\partial F_V}{\\partial V} & \\frac{\\partial F_V}{\\partial w}\\\\\n",
        "    \\frac{\\partial F_w}{\\partial V} & \\frac{\\partial F_w}{\\partial w}\n",
        "\\end{bmatrix}_{\\mathbf{x}_0}  (\\mathbf{x} -\\mathbf{x_0})$$\n",
        "\n",
        "because for $\\mathbf{x} =\\mathbf{x_0}$ the derivative must be zero. This can be rewritten simply as:\n",
        "$$\\mathbf{\\dot{\\hat x}}= \\mathrm{J} \\mathbf{\\hat x}$$\n",
        "\n",
        "This matrix $\\mathrm{J}$ is called a **Jacobian** (scary name!). But it only has 4 components, which we can derive analytically (with pen and paper) from eq. 5a-5b:"
      ],
      "metadata": {
        "id": "zztPsQ-R-bdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nullcline_intersection(V_thr,i_ext,beta):\n",
        "  diff = lambda x: np.abs(V_nullcline(x,V_thr,i_ext) - w_nullcline(x,beta))\n",
        "  return minimize(diff,0.4).x[0]\n",
        "\n",
        "\n",
        "eps = 0.01\n",
        "V = find_nullcline_intersection(V_thr,i_ext,beta)\n",
        "print(f'Nullclines intersect at V={V:.3f}')\n",
        "# J = np.array([[..., ...],[...,...]])  # FILL IN\n",
        "\n",
        "print(\"Eigenvalues of a Jacobian: \",np.linalg.eig(J)[0])"
      ],
      "metadata": {
        "id": "IGVDBzxuErWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Think!**\n",
        "So, is it stable?"
      ],
      "metadata": {
        "id": "zgeYXh2GC1WF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Global stability"
      ],
      "metadata": {
        "id": "kndVlnjuHI34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us take a step back. Literally. Let us zoom out on that phase portrait:"
      ],
      "metadata": {
        "id": "XJ8wfv6aGvO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i_ext, V_thr, beta = 0.1, 0.2, 0.4\n",
        "plot_FHN_phase_portrait(i_ext,V_thr,beta, eps=.1,\n",
        "                        V_min=-5, V_max=5, w_min=-50, w_max=50,\n",
        "                        V_null = V_nullcline, w_null = w_nullcline)"
      ],
      "metadata": {
        "id": "6D5yzQeSHUuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Think!**\n",
        "We see that all of the arrows are point towards the cubic V-nullcline. But why are they horizontal?\n"
      ],
      "metadata": {
        "id": "6s8EKaABJyBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After they reach the cubic V-nulcline, V does not change anymore, but $ dw/dt \\sim -w$ for large $w$. So, overall, the system is attracter towards (0,0) on a global scale.\n",
        "\n",
        "#### **Summarize and Think!**\n",
        "\n",
        "What should happen on intermediate timescale if:\n",
        "1. **locally**: two nullclines have only one intersection which is a *repeller*\n",
        "2. **globally** the states are *attracted* towards (0,0)\n",
        "\n",
        "?\n"
      ],
      "metadata": {
        "id": "Dekbfp9goUFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing trajectories"
      ],
      "metadata": {
        "id": "Ec8midjSBJUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With all the knowledge you possess now, you can figure out all possible behaviors of this system with only pen and paper. But it is a lot of work! Instead, we can take a fun route and visulize some trajectories starting from random initial conditions:"
      ],
      "metadata": {
        "id": "CcTLCvs7nHqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_FHN_trajectories(i_ext,V_thr,beta,\n",
        "                          N=10, T=20000, dt=.1,eps=0.01,n=30):\n",
        "  '''\n",
        "    Plots a trajectories for a FitzHugh-Nagumo model (eq. 5)\n",
        "  '''\n",
        "  fig, ax = plt.subplots(1,2,figsize=(15,5),gridspec_kw={'width_ratios': [1,2]})\n",
        "\n",
        "  # plot trajectories\n",
        "  # V_dot = lambda V, w: ... # FILL IN\n",
        "  # w_dot = lambda V, w: ... # FILL IN\n",
        "  # generate some initial conditions\n",
        "  V_0 = np.random.randn(N) * .5 + 0.5\n",
        "  w_0 = np.random.randn(N) * .02 + .05\n",
        "  # create an empty array for storing solutions \n",
        "  traject = np.empty((2,T+1,N))\n",
        "  traject[:,0] = np.array([V_0, w_0])\n",
        "  for t in range(T):\n",
        "    traject[:,t+1] = np.clip(\n",
        "                      [traject[0,t] + V_dot(*traject[:,t])*dt,\n",
        "                      traject[1,t] + w_dot(*traject[:,t])*dt],-10,10)\n",
        "  for i in range(N):\n",
        "    ax[0].plot(*traject[...,i],alpha=.3,linewidth=5)\n",
        "    ax[1].plot(traject[0,:,i])\n",
        "\n",
        "  # plot nullclines\n",
        "  global V_nullcline, w_nullcline\n",
        "  V_grid = np.linspace(-.5, 1.2, n) # a 1D activator grid\n",
        "  ax[0].plot(V_grid,V_nullcline(V_grid,V_thr,i_ext),c='k')\n",
        "  ax[0].plot(V_grid,w_nullcline(V_grid,beta),c='k')\n",
        "  \n",
        "  ax[0].set_xlabel('fast activator V')\n",
        "  ax[0].set_ylabel('slow inhibitor w')\n",
        "  ax[1].set_ylabel('fast activator V')\n",
        "  ax[1].set_xlabel('time')\n",
        "  ax[0].set_xlim([-.5,1.2])\n",
        "  ax[1].set_ylim([-.5,1.2])\n",
        "  ax[0].set_ylim([-.1,.2])\n",
        "\n",
        "@widgets.interact\n",
        "def interactive_FHN_trajectories(i_ext=widgets.FloatSlider(min=-.2, max=.3, value=0,step=.01), \n",
        "                            V_thr=widgets.FloatSlider(min=0, max=1, value=0.2),\n",
        "                            beta=widgets.FloatSlider(min=0.05, max=.5, value=.25, step=.01),):\n",
        "  plot_FHN_trajectories(i_ext,V_thr,beta)"
      ],
      "metadata": {
        "id": "ywfSLU6ipoeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yay, we've got action potentials!\n",
        "\n",
        "Not particularly beautiful action potentials (well, it is an approximated, reduced model), but still action potentials!\n",
        "\n",
        "If you don't see anything like action potentials, try stimulating the FHN neuron just a little bit with the external current $i_{ext}$. It makes sense, right? The neuron responds to some inputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "T7TKHX_DBPIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Think: linear vs nonlinear oscillations**\n",
        "\n",
        "Now that you've seen a linear oscillator and a non-linear oscillator (limit cycle), what is the key qualitative difference between them? How would the amplitude of oscillations change if you change initial conditions?"
      ],
      "metadata": {
        "id": "8__UNIH962G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "In the second part of the tutorial, we:\n",
        "1. Learned that nonlinear systems can have not just *one* but *many* fixed points\n",
        "2. Learned how to linearize the dynamical system about a fixed point and check its local stability\n",
        "3. Learned a new type of an attractor: a limit cycle!\n",
        "4. Simulated some action potentials!"
      ],
      "metadata": {
        "id": "32pRn7au6len"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projects\n",
        "\n",
        "**Beginner:**  In this tutorial we considered mostly autonomous dynamical systems, including a line attractor. Although, a line attractor has interesting input-processing properties: it can integrate inputs! Implement a 2D line attractor with 1D external input (e.g. white noise):\n",
        "$$\\mathbf{\\dot x} = A\\mathbf{x} + B\\mathbf{u} + \\mathbf{b}$$\n",
        "and demonstrate input integration. What should be the relationship between matrices $A$ and $B$ for integration to work?\n",
        "\n",
        "**Intermediate:** Between linear and non-linear models of dynamics, there is an intermediate class of models: piecewise-linear models. These models are linear within a certain area of a phase plane, but can generally exhibit quite complex behavior. Consider a 2D dynamical system:\n",
        "\n",
        "$$\\mathbf{\\dot x} = {\\begin{bmatrix}\n",
        "    \\dot x_1 \\\\\n",
        "    \\dot x_2\n",
        "\\end{bmatrix}} = \\begin{cases} \n",
        "      A_-\\mathbf{x} + \\mathbf{b_-} & x_1 < 0 \\\\\n",
        "      A_+\\mathbf{x} + \\mathbf{b_+} & x_1 \\geq 0 \n",
        "   \\end{cases} $$\n",
        "\n",
        "Implement this system and analyse its phase portrait and trajectories in the phase space. \n",
        "\n",
        "How does the stability depend on the parameters of the model? What is the period of oscillations?\n",
        "\n",
        "Extra question$^*$: is it possible to obtain a figure-of-eight trajectory in such system?\n",
        "\n",
        "**Hard and extra-hard:** see part 4 of the tutorial."
      ],
      "metadata": {
        "id": "H19D2ahHdTkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parts 3: Modelling dynamics based on data\n",
        "\n",
        "[Go to the next notebook](https://github.com/NinelK/IMBIZO2022_DS_Tutorial/blob/main/DS_Tutorial_Part_3.ipynb)"
      ],
      "metadata": {
        "id": "jE2TTKmgzwIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. Izhikevich, Eugene M. [Dynamical systems in neuroscience.](https://www.izhikevich.org/publications/dsn.pdf) MIT press, 2007.\n",
        "\n",
        "2. Gerstner, Wulfram, et al. [Neuronal dynamics](https://neuronaldynamics.epfl.ch/index.html): From single neurons to networks and models of cognition. Cambridge University Press, 2014.\n",
        "\n",
        "<!-- ## Other great tutorials: -->\n",
        "3. Linear dynamical systems by Bing Wen Brunton and Alice Schwarze [Neuromatch: W2D2](https://compneuro.neuromatch.io/tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1.html), 2020-now"
      ],
      "metadata": {
        "id": "kblnhvBQ9GvC"
      }
    }
  ]
}